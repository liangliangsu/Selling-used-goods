{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import keras.applications.resnet50 as resnet50\n",
    "\n",
    "import keras.applications.inception_v3 as inception_v3\n",
    "from keras.applications.inception_v3 import preprocess_input as incept_preprocess_input\n",
    "from keras.applications.inception_v3 import decode_predictions as incept_decode_predictions\n",
    "\n",
    "\"\"\"import keras.applications.xception as xception\n",
    "from keras.applications.xception import preprocess_input as xcept_preprocess_input\n",
    "from keras.applications.xception import decode_predictions as xcept_decode_predictions\n",
    "\"\"\"\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features exist!\n"
     ]
    }
   ],
   "source": [
    "#folder='image'\n",
    "folder='train_jpg_4'\n",
    "#folder='test_jpg'\n",
    "images_dir='E:\\\\kaggle\\\\Avito Demand Prediction Challenge\\\\'+folder+'\\\\'\n",
    "indexlist= os.listdir()\n",
    "if 'index'+folder+'.csv' in indexlist:\n",
    "    features=pd.read_csv('index'+folder+'.csv',header=0)\n",
    "    print ('features exist!')\n",
    "else:\n",
    "    image_files = os.listdir(images_dir)\n",
    "    features = pd.DataFrame(image_files, columns=['image'])\n",
    "    features.to_csv('index'+folder+'.csv', index=False)   \n",
    "    print ('features do not exist, creat one!' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is train_jpg_4 , block is 0 , progress is 0 k\n",
      "00:00:13\n",
      "Folder is train_jpg_4 , block is 0 , progress is 5 k\n",
      "00:03:59\n",
      "Folder is train_jpg_4 , block is 0 , progress is 10 k\n",
      "00:07:59\n",
      "Folder is train_jpg_4 , block is 0 , progress is 15 k\n",
      "00:12:02\n",
      "Folder is train_jpg_4 , block is 0 , progress is 20 k\n",
      "00:16:00\n",
      "Folder is train_jpg_4 , block is 0 , progress is 25 k\n",
      "00:19:57\n",
      "Folder is train_jpg_4 , block is 0 , progress is 30 k\n",
      "00:23:53\n",
      "Folder is train_jpg_4 , block is 0 , progress is 35 k\n",
      "00:27:46\n",
      "Folder is train_jpg_4 , block is 0 , progress is 40 k\n",
      "00:31:39\n",
      "Folder is train_jpg_4 , block is 0 , progress is 45 k\n",
      "00:35:31\n",
      "Folder is train_jpg_4 , block is 0 , progress is 50 k\n",
      "00:39:20\n",
      "Folder is train_jpg_4 , block is 0 , progress is 55 k\n",
      "00:43:08\n",
      "Folder is train_jpg_4 , block is 1 , progress is 0 k\n",
      "00:43:38\n",
      "Folder is train_jpg_4 , block is 1 , progress is 5 k\n",
      "00:47:24\n",
      "Folder is train_jpg_4 , block is 1 , progress is 10 k\n",
      "00:51:09\n",
      "Folder is train_jpg_4 , block is 1 , progress is 15 k\n",
      "00:54:52\n",
      "Folder is train_jpg_4 , block is 1 , progress is 20 k\n",
      "00:58:35\n",
      "Folder is train_jpg_4 , block is 1 , progress is 25 k\n",
      "01:02:18\n",
      "Folder is train_jpg_4 , block is 1 , progress is 30 k\n",
      "01:05:58\n",
      "Folder is train_jpg_4 , block is 1 , progress is 35 k\n",
      "01:09:37\n",
      "Folder is train_jpg_4 , block is 1 , progress is 40 k\n",
      "01:13:17\n",
      "Folder is train_jpg_4 , block is 1 , progress is 45 k\n",
      "01:16:55\n",
      "Folder is train_jpg_4 , block is 1 , progress is 50 k\n",
      "01:20:32\n",
      "Folder is train_jpg_4 , block is 1 , progress is 55 k\n",
      "01:24:08\n",
      "Folder is train_jpg_4 , block is 2 , progress is 0 k\n",
      "01:24:37\n",
      "Folder is train_jpg_4 , block is 2 , progress is 5 k\n",
      "01:28:11\n",
      "Folder is train_jpg_4 , block is 2 , progress is 10 k\n",
      "01:31:45\n",
      "Folder is train_jpg_4 , block is 2 , progress is 15 k\n",
      "01:35:19\n",
      "Folder is train_jpg_4 , block is 2 , progress is 20 k\n",
      "01:38:53\n",
      "Folder is train_jpg_4 , block is 2 , progress is 25 k\n",
      "01:42:47\n",
      "Folder is train_jpg_4 , block is 2 , progress is 30 k\n",
      "01:47:30\n",
      "Folder is train_jpg_4 , block is 2 , progress is 35 k\n",
      "01:51:00\n",
      "Folder is train_jpg_4 , block is 2 , progress is 40 k\n",
      "01:54:31\n",
      "Folder is train_jpg_4 , block is 2 , progress is 45 k\n",
      "01:58:01\n",
      "Folder is train_jpg_4 , block is 2 , progress is 50 k\n",
      "02:01:30\n",
      "Folder is train_jpg_4 , block is 2 , progress is 55 k\n",
      "02:05:00\n",
      "Folder is train_jpg_4 , block is 3 , progress is 0 k\n",
      "02:05:28\n",
      "Folder is train_jpg_4 , block is 3 , progress is 5 k\n",
      "02:08:57\n",
      "Folder is train_jpg_4 , block is 3 , progress is 10 k\n",
      "02:12:25\n",
      "Folder is train_jpg_4 , block is 3 , progress is 15 k\n",
      "02:15:55\n",
      "Folder is train_jpg_4 , block is 3 , progress is 20 k\n",
      "02:19:24\n",
      "Folder is train_jpg_4 , block is 3 , progress is 25 k\n",
      "02:22:53\n",
      "Folder is train_jpg_4 , block is 3 , progress is 30 k\n",
      "02:26:23\n",
      "Folder is train_jpg_4 , block is 3 , progress is 35 k\n",
      "02:29:51\n",
      "Folder is train_jpg_4 , block is 3 , progress is 40 k\n",
      "02:33:20\n",
      "Folder is train_jpg_4 , block is 3 , progress is 45 k\n",
      "02:36:50\n",
      "Folder is train_jpg_4 , block is 3 , progress is 50 k\n",
      "02:40:20\n",
      "Folder is train_jpg_4 , block is 3 , progress is 55 k\n",
      "02:43:49\n",
      "Folder is train_jpg_4 , block is 4 , progress is 0 k\n",
      "02:44:16\n",
      "Folder is train_jpg_4 , block is 4 , progress is 5 k\n",
      "02:47:46\n",
      "Folder is train_jpg_4 , block is 4 , progress is 10 k\n",
      "02:51:17\n",
      "Folder is train_jpg_4 , block is 4 , progress is 15 k\n",
      "02:54:46\n",
      "Folder is train_jpg_4 , block is 4 , progress is 20 k\n",
      "02:58:16\n",
      "Folder is train_jpg_4 , block is 4 , progress is 25 k\n",
      "03:01:45\n",
      "Folder is train_jpg_4 , block is 4 , progress is 30 k\n",
      "03:05:15\n",
      "Folder is train_jpg_4 , block is 4 , progress is 35 k\n",
      "03:08:44\n",
      "Folder is train_jpg_4 , block is 4 , progress is 40 k\n",
      "03:12:14\n",
      "Folder is train_jpg_4 , block is 4 , progress is 45 k\n",
      "03:15:43\n",
      "Folder is train_jpg_4 , block is 4 , progress is 50 k\n",
      "03:19:10\n",
      "Folder is train_jpg_4 , block is 4 , progress is 55 k\n",
      "03:22:42\n"
     ]
    }
   ],
   "source": [
    "splitnum=5\n",
    "length=int(len(features)/splitnum)\n",
    "binsize=[x*length for x in range(splitnum)]\n",
    "binsize.append(len(features))\n",
    "start_time = time.time()\n",
    "\n",
    "#model = resnet50.ResNet50(weights='imagenet')\n",
    "inception_model = inception_v3.InceptionV3(weights='imagenet')\n",
    "#xception_model = xception.Xception(weights='imagenet')\n",
    "\n",
    "\n",
    "for i in range(0,splitnum):\n",
    "    count=0\n",
    "    incept_1=[]\n",
    "    incept_2=[]\n",
    "    incept_3=[]\n",
    "    incept_4=[]\n",
    "    incept_5=[]\n",
    "    \"\"\"xcept_1=[]\n",
    "    xcept_2=[]\n",
    "    xcept_3=[]\n",
    "    xcept_4=[]\n",
    "    xcept_5=[]\"\"\"\n",
    "    indexs=[]\n",
    "    \n",
    "    \n",
    "    for n in range(binsize[i],binsize[i+1]):\n",
    "        im=features.iloc[n]['image']\n",
    "        indexs.append(im)\n",
    "        \n",
    "        try:\n",
    "            img_path=images_dir+im\n",
    "            img = image.load_img(img_path, target_size=(224, 224))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            \n",
    "            incept_x = incept_preprocess_input(x)\n",
    "            incept_preds = inception_model.predict(incept_x)\n",
    "            result= incept_decode_predictions(incept_preds, top=5)[0]\n",
    "            incept_1.append(result[0][1:3])\n",
    "            incept_2.append(result[1][1:3])\n",
    "            incept_3.append(result[2][1:3])\n",
    "            incept_4.append(result[3][1:3])\n",
    "            incept_5.append(result[4][1:3])\n",
    "            \n",
    "            \"\"\"xcept_x = xcept_preprocess_input(x)\n",
    "            xcept_preds = xception_model.predict(xcept_x)\n",
    "            result= xcept_decode_predictions(xcept_preds, top=5)[0]\n",
    "            xcept_1.append(result[0][1:3])\n",
    "            xcept_2.append(result[1][1:3])\n",
    "            xcept_3.append(result[2][1:3])\n",
    "            xcept_4.append(result[3][1:3])\n",
    "            xcept_5.append(result[4][1:3])\"\"\"\n",
    "            \n",
    "            \n",
    "        except:            \n",
    "            incept_1.append(('image broken',0.0))\n",
    "            incept_2.append(('image broken',0.0))\n",
    "            incept_3.append(('image broken',0.0))\n",
    "            incept_4.append(('image broken',0.0))\n",
    "            incept_5.append(('image broken',0.0))\n",
    "            \"\"\"xcept_1.append(('image broken',0.0))\n",
    "            xcept_2.append(('image broken',0.0))\n",
    "            xcept_3.append(('image broken',0.0))\n",
    "            xcept_4.append(('image broken',0.0))\n",
    "            xcept_5.append(('image broken',0.0))\"\"\"   \n",
    "            \n",
    "            print ('cannot identify image file',im)\n",
    "                    \n",
    "        if (count%5000)==0:\n",
    "            print ('Folder is',folder, ', block is',i, ', progress is',int(count/1000),'k')\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "        count+=1\n",
    "    \n",
    "    filename1=folder+'_incept_%d.csv'%(i)\n",
    "    result = {'indexs':indexs, \n",
    "              'incept_1': incept_1, 'incept_2': incept_2, 'incept_3':incept_3, 'incept_4':incept_4, 'incept_5':incept_5}\n",
    "    result = pd.DataFrame(data=result)\n",
    "    col=['indexs','incept_1', 'incept_2', 'incept_3', 'incept_4', 'incept_5']\n",
    "    result=result[col]\n",
    "    result.to_csv(filename1, index=False)    \n",
    "    del result, incept_1, incept_2, incept_3, incept_4, incept_5,indexs\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    \"\"\"filename2=folder+'_xcept_%d.csv'%(i)\n",
    "    result = {'indexs':indexs, \n",
    "              'xcept_1': xcept_1, 'xcept_2': xcept_2, 'xcept_3':xcept_3, 'xcept_4':xcept_4, 'xcept_5':xcept_5}\n",
    "    result = pd.DataFrame(data=result)\n",
    "    col=['indexs','xcept_1', 'xcept_2', 'xcept_3', 'xcept_4', 'xcept_5']\n",
    "    result=result[col]\n",
    "    result.to_csv(filename2, index=False)    \n",
    "    del result, xcept_1, xcept_2, xcept_3, xcept_4, xcept_5,indexs\n",
    "    gc.collect()\"\"\"\n",
    "    \n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
